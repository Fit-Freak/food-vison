{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1323bc75",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "The end goal of this step is to prepare the dataset for training a machine learning model. This involves several key tasks:\n",
    "\n",
    "1. Downloading the dataset from a specified source.\n",
    "2. Putting the dataset into a structured format suitable for analysis.\n",
    "3. Splitting the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6d9d4",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Environment(Enum):\n",
    "    COLAB = \"Colab\"\n",
    "    LOCAL = \"Local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44db8fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ Current Environment: Local\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸŒ Current Environment: {Environment.LOCAL.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e20cf",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b3f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Required Libraries ...\n",
      "ðŸ†— All required libraries are installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing Required Libraries ...\")\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"ðŸ†— All required libraries are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a936e8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†— ipywidgets installed for local environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "if Environment.LOCAL:\n",
    "    !pip install -q ipywidgets\n",
    "    print(\"ðŸ†— ipywidgets installed for local environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6b1fc",
   "metadata": {},
   "source": [
    "## Setup Folder Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data/foodSeg103')\n",
    "train_img_dir = data_dir / 'train' / 'images'\n",
    "train_lbl_dir = data_dir / 'train' / 'labels'\n",
    "validation_img_dir = data_dir / 'validation' / 'images'\n",
    "validation_lbl_dir = data_dir / 'validation' / 'labels'\n",
    "\n",
    "for d in [train_img_dir, train_lbl_dir, validation_img_dir, validation_lbl_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2501878",
   "metadata": {},
   "source": [
    "# Download Dataset from Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833fbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def download_dataset(split_ds, img_dir, lbl_dir):\n",
    "    for sample in tqdm(split_ds, desc=f\"Saving {img_dir.parent.name}\"):\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        image_id = sample[\"id\"]\n",
    "\n",
    "        # Save image\n",
    "        img_path = img_dir / f\"{image_id}.jpg\"\n",
    "        lbl_path = lbl_dir / f\"{image_id}.png\"\n",
    "\n",
    "        image.save(img_path)\n",
    "        label.save(lbl_path)\n",
    "\n",
    "    print(f\"âœ… Saved {len(split_ds)} samples to {img_dir.parent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95bb668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data\\foodSeg103 directory exists.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset splits\n",
    "train_ds = load_dataset(\"EduardoPacheco/FoodSeg103\", split=\"train\")\n",
    "val_ds = load_dataset(\"EduardoPacheco/FoodSeg103\", split=\"validation\")\n",
    "\n",
    "# If the data folder doesn't exist, download it and prepare it...\n",
    "if data_dir.is_dir():\n",
    "    print(f\"âœ… {data_dir} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {data_dir} directory, creating one...\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save both splits\n",
    "    download_dataset(train_ds, train_img_dir, train_lbl_dir)\n",
    "    download_dataset(val_ds, val_img_dir, val_lbl_dir)\n",
    "\n",
    "    print(f'âœ… Dataset saved in: {data_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
