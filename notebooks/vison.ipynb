{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "076e0c79",
      "metadata": {
        "id": "076e0c79"
      },
      "source": [
        "# Food Vision With SegFormer and Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "Ad_gK2nNk7tO"
      },
      "id": "Ad_gK2nNk7tO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization Helpers"
      ],
      "metadata": {
        "id": "a_zEzsemL651"
      },
      "id": "a_zEzsemL651"
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_image_with_mask(image, mask=None, alpha=0.5, ignore_index=255):\n",
        "    \"\"\"\n",
        "    Visualize an image, its segmentation mask, and overlay.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray or PIL.Image.Image): RGB image.\n",
        "        mask (np.ndarray or PIL.Image.Image): Segmentation mask (H x W).\n",
        "        alpha (float): Transparency for overlay blending.\n",
        "        ignore_index (int): Mask value to ignore (e.g., 255).\n",
        "    \"\"\"\n",
        "    # --- Convert image to NumPy ---\n",
        "    img = np.array(image)\n",
        "    if img.ndim == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    if img.dtype != np.uint8:\n",
        "        img = np.clip(img * 255, 0, 255).astype(np.uint8)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    mask_np = None\n",
        "    if mask is not None:\n",
        "        mask_np = np.array(mask, dtype=np.int64)\n",
        "\n",
        "        # --- Resize mask to match image if needed ---\n",
        "        if mask_np.shape[:2] != (h, w):\n",
        "            mask_np = cv2.resize(mask_np, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # --- Deterministic color map (tab20 colormap) ---\n",
        "        cmap = plt.get_cmap(\"tab20\", np.max(mask_np) + 1)\n",
        "        color_mask = np.zeros_like(img, dtype=np.uint8)\n",
        "\n",
        "        for cls_id in np.unique(mask_np):\n",
        "            if cls_id == ignore_index:\n",
        "                color = (128, 128, 128)  # gray for ignore\n",
        "            elif cls_id == 0:\n",
        "                color = (30, 30, 30)  # dark gray for background\n",
        "            else:\n",
        "                color = (np.array(cmap(cls_id)[:3]) * 255).astype(np.uint8)\n",
        "            color_mask[mask_np == cls_id] = color\n",
        "\n",
        "        # --- Blend overlay ---\n",
        "        blended = cv2.addWeighted(img, 1 - alpha, color_mask, alpha, 0)\n",
        "    else:\n",
        "        blended = img\n",
        "\n",
        "    # --- Plot ---\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"üñºÔ∏è Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    if mask_np is not None:\n",
        "        plt.imshow(mask_np, cmap=\"tab20\", vmin=0, vmax=np.max(mask_np))\n",
        "        plt.title(\"üé≠ Segmentation Mask\")\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, \"No mask\", ha=\"center\", va=\"center\", fontsize=12)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(blended)\n",
        "    plt.title(\"‚ú® Overlay (Image + Mask)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Print metadata ---\n",
        "    if mask_np is not None:\n",
        "        valid = mask_np != ignore_index\n",
        "        coverage = np.count_nonzero(valid) / mask_np.size * 100\n",
        "        print(f\"‚úÖ Mask coverage: {coverage:.2f}% of image area\")\n",
        "        print(f\"üü¢ Unique classes: {np.unique(mask_np[valid]).tolist()}\")\n",
        "        print(f\"üìè Image size: {img.shape}\")\n",
        "        print(f\"üé≠ Mask size: {mask_np.shape}\")"
      ],
      "metadata": {
        "id": "GoK_6_1D6WDz"
      },
      "id": "GoK_6_1D6WDz",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unnormalize_image(\n",
        "    tensor: torch.Tensor,\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225)\n",
        "):\n",
        "    \"\"\"\n",
        "    Reverse ImageNet normalization to make images display correctly.\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Normalized image tensor (C, H, W)\n",
        "    Returns:\n",
        "        torch.Tensor: Unnormalized tensor in [0, 1]\n",
        "    \"\"\"\n",
        "    tensor = tensor.detach().cpu()\n",
        "    if tensor.ndim != 3 or tensor.shape[0] != 3:\n",
        "        raise ValueError(f\"Expected shape (3,H,W), got {tensor.shape}\")\n",
        "    mean = torch.tensor(mean).view(3, 1, 1)\n",
        "    std = torch.tensor(std).view(3, 1, 1)\n",
        "    tensor = tensor * std + mean\n",
        "    return torch.clamp(tensor, 0, 1)"
      ],
      "metadata": {
        "id": "jfdmE5kML5xY"
      },
      "id": "jfdmE5kML5xY",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_segmentation(images, masks, preds, n=4, save_path=None, unnormalize=True):\n",
        "    \"\"\"\n",
        "    Visualize input images, ground truth masks, and model predictions.\n",
        "    Args:\n",
        "        images: (B,C,H,W)\n",
        "        masks:  (B,H,W)\n",
        "        preds:  (B,H,W)\n",
        "    \"\"\"\n",
        "    images, masks, preds = images.cpu(), masks.cpu(), preds.cpu()\n",
        "    plt.figure(figsize=(12, n * 3))\n",
        "    cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "    for i in range(min(n, images.size(0))):\n",
        "        img = unnormalize_image(images[i]) if unnormalize else torch.clamp(images[i], 0, 1)\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # --- Original ---\n",
        "        plt.subplot(n, 3, i * 3 + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(\"Original\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # --- Ground Truth ---\n",
        "        plt.subplot(n, 3, i * 3 + 2)\n",
        "        plt.imshow(masks[i], cmap=cmap, vmin=0, vmax=torch.max(masks))\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # --- Prediction ---\n",
        "        plt.subplot(n, 3, i * 3 + 3)\n",
        "        plt.imshow(preds[i], cmap=cmap, vmin=0, vmax=torch.max(preds))\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
        "        print(f\"üñºÔ∏è Saved segmentation visualization to: {save_path}\")\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "Lz7YhCM_j39C"
      },
      "id": "Lz7YhCM_j39C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(results, save_path=None):\n",
        "    \"\"\"Visualize training metrics (loss, acc, mIoU) over epochs.\"\"\"\n",
        "    epochs = range(1, len(results[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 5))\n",
        "\n",
        "    # ---- Loss ----\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(epochs, results[\"train_loss\"], \"b-\", marker=\"o\", label=\"Train\")\n",
        "    plt.plot(epochs, results[\"test_loss\"], \"r-\", marker=\"o\", label=\"Val\")\n",
        "    plt.title(\"Loss per Epoch\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.grid(True); plt.legend()\n",
        "\n",
        "    # ---- Accuracy ----\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(epochs, results[\"train_acc\"], \"b-\", marker=\"o\", label=\"Train\")\n",
        "    plt.plot(epochs, results[\"test_acc\"], \"r-\", marker=\"o\", label=\"Val\")\n",
        "    plt.title(\"Pixel Accuracy per Epoch\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.grid(True); plt.legend()\n",
        "\n",
        "    # ---- mIoU ----\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(epochs, results[\"train_iou\"], \"b-\", marker=\"o\", label=\"Train\")\n",
        "    plt.plot(epochs, results[\"test_iou\"], \"r-\", marker=\"o\", label=\"Val\")\n",
        "    plt.title(\"Mean IoU per Epoch\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"mIoU\"); plt.grid(True); plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
        "        print(f\"‚úÖ Saved training curves to {save_path}\")\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "asyVXTl1j7BP"
      },
      "id": "asyVXTl1j7BP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_random_sample(dataset: torch.utils.data.Dataset, seed: int = 42):\n",
        "    \"\"\"\n",
        "    Displays a random image and its mask from a PyTorch dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (Dataset): A PyTorch dataset that returns (image, mask) pairs.\n",
        "    \"\"\"\n",
        "    # Pick random index\n",
        "    idx = random.randint(0, len(dataset) - 1)\n",
        "    image, mask = dataset[idx]\n",
        "\n",
        "    # If tensors ‚Üí convert to NumPy (for plotting)\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image_np = image.permute(1, 2, 0).numpy()  # CHW ‚Üí HWC\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "    else:\n",
        "        image_np = np.array(image)\n",
        "\n",
        "    if isinstance(mask, torch.Tensor):\n",
        "        mask_np = mask.numpy()\n",
        "    else:\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "    # --- Print metadata ---\n",
        "    print(f\"üñºÔ∏è Sample Index: {idx}\")\n",
        "    # --- Visualize using helper ---\n",
        "    visualize_image_with_mask(image_np, mask_np)"
      ],
      "metadata": {
        "id": "VeH8PRas6hus"
      },
      "id": "VeH8PRas6hus",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric Helpers"
      ],
      "metadata": {
        "id": "UDsOUbADMHgR"
      },
      "id": "UDsOUbADMHgR"
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(preds, labels, ignore_index: int = 255):\n",
        "    \"\"\"Compute per-pixel accuracy (ignoring 'ignore_index' pixels).\"\"\"\n",
        "    valid_mask = labels != ignore_index\n",
        "    correct = (preds[valid_mask] == labels[valid_mask]).sum().item()\n",
        "    total = valid_mask.sum().item()\n",
        "    return correct / total if total > 0 else 0.0"
      ],
      "metadata": {
        "id": "b59CuLoWj_lO"
      },
      "id": "b59CuLoWj_lO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection_over_union(preds, labels, num_classes: int, ignore_index: int = 255):\n",
        "    \"\"\"Compute mean Intersection-over-Union (mIoU), ignoring 'ignore_index' pixels.\"\"\"\n",
        "    preds = preds.detach().cpu()\n",
        "    labels = labels.detach().cpu()\n",
        "\n",
        "    # Mask out ignored pixels\n",
        "    mask = labels != ignore_index\n",
        "    preds = preds[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    ious = []\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = preds == cls\n",
        "        label_inds = labels == cls\n",
        "        intersection = (pred_inds & label_inds).sum().item()\n",
        "        union = (pred_inds | label_inds).sum().item()\n",
        "        if union == 0:\n",
        "            continue\n",
        "        ious.append(intersection / union)\n",
        "\n",
        "    return np.mean(ious) if ious else 0.0"
      ],
      "metadata": {
        "id": "3xXwxXteMKhA"
      },
      "id": "3xXwxXteMKhA",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoint Utilities"
      ],
      "metadata": {
        "id": "CGszaJPHMQ6L"
      },
      "id": "CGszaJPHMQ6L"
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer=None, scheduler=None, epoch=0, best_miou=0.0, path=\"ckpts\", filename=None):\n",
        "    \"\"\"\n",
        "    Save model weights + optimizer + scheduler state (for training resume).\n",
        "    \"\"\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    filename = filename or f\"segformer_finetuned_epoch_{epoch}.ckpt\"\n",
        "    checkpoint_path = os.path.join(path, filename)\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict() if optimizer else None,\n",
        "        \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None,\n",
        "        \"best_miou\": best_miou,\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"‚úÖ Checkpoint saved: {checkpoint_path} (Best mIoU: {best_miou:.4f})\")\n",
        "\n",
        "def save_huggingface_export(model, processor, export_dir=\"./ckpts/segformer_finetuned\"):\n",
        "    \"\"\"\n",
        "    Save model + processor in Hugging Face format (for inference and sharing).\n",
        "    \"\"\"\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "    model.save_pretrained(export_dir)\n",
        "    processor.save_pretrained(export_dir)\n",
        "    print(f\"üéØ Exported Hugging Face model and processor to: {export_dir}\")"
      ],
      "metadata": {
        "id": "4BIoNMNOMLaS"
      },
      "id": "4BIoNMNOMLaS",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
        "\n",
        "def load_checkpoint(model, path, optimizer=None, scheduler=None, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Load checkpoint (for resuming training).\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    if optimizer and checkpoint.get(\"optimizer_state_dict\"):\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    if scheduler and checkpoint.get(\"scheduler_state_dict\"):\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "    epoch = checkpoint.get(\"epoch\", 0)\n",
        "    best_miou = checkpoint.get(\"best_miou\", 0.0)\n",
        "    print(f\"‚úÖ Loaded checkpoint from epoch {epoch+1} | Best mIoU={best_miou:.4f}\")\n",
        "    return checkpoint\n",
        "\n",
        "def load_huggingface_export(model_dir=\"./ckpts/segformer_finetuned\", device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Load model and processor saved via Hugging Face API (for inference).\n",
        "    \"\"\"\n",
        "    model = SegformerForSemanticSegmentation.from_pretrained(export_dir)\n",
        "    processor = SegformerImageProcessor.from_pretrained(export_dir)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"üöÄ Loaded Hugging Face model and processor from: {export_dir}\")\n",
        "    return model, processor"
      ],
      "metadata": {
        "id": "fEhMuxgVcXKA"
      },
      "id": "fEhMuxgVcXKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38fc581f",
      "metadata": {
        "id": "38fc581f"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "98cf102d",
      "metadata": {
        "id": "98cf102d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from typing import Tuple, Optional, Dict, List\n",
        "from enum import Enum\n",
        "import json\n",
        "# Essentials\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "# Hugging Face\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5db7ae64",
      "metadata": {
        "id": "5db7ae64"
      },
      "source": [
        "## Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "24555e94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24555e94",
        "outputId": "fa025208-0aea-410b-e28d-f100daa76794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ torch version: 2.8.0+cu126\n",
            "‚úÖ torchvision version: 0.23.0+cu126\n"
          ]
        }
      ],
      "source": [
        "from packaging import version\n",
        "\n",
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "required_torch = \"1.12.0\"\n",
        "required_torchvision = \"0.13.0\"\n",
        "\n",
        "if version.parse(torch.__version__) < version.parse(required_torch) or \\\n",
        "   version.parse(torchvision.__version__) < version.parse(required_torchvision):\n",
        "    print(\"[INFO] torch/torchvision versions not as required, installing latest versions.\")\n",
        "    # You can change cu121 to cu118 or cpu as needed\n",
        "    import os\n",
        "    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "    # Reload torch and torchvision to reflect new versions\n",
        "    import importlib\n",
        "    importlib.reload(torch)\n",
        "    importlib.reload(torchvision)\n",
        "\n",
        "print(f\"‚úÖ torch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ebc846",
      "metadata": {
        "id": "00ebc846"
      },
      "source": [
        "## Setup Platform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive\n",
        "\n",
        "Uncomment the lines to mount google drive if using **google colab**."
      ],
      "metadata": {
        "id": "Coj0GjGfRVPg"
      },
      "id": "Coj0GjGfRVPg"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGk5o_qbRS-I",
        "outputId": "d04f6818-09a8-4c1e-f5f8-b188451698b6"
      },
      "id": "xGk5o_qbRS-I",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b1c4f17",
      "metadata": {
        "id": "1b1c4f17"
      },
      "source": [
        "## Setup Device-Agnostic Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9f2e755d",
      "metadata": {
        "id": "9f2e755d"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e9262e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9262e45",
        "outputId": "6091fb1d-13df-4508-f62f-603d619d8b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using Device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(f\"‚úÖ Using Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ef162f",
      "metadata": {
        "id": "61ef162f"
      },
      "source": [
        "## Setup Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ea96d20",
      "metadata": {
        "id": "0ea96d20"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed: int = 42):\n",
        "    \"\"\"Sets seed for reproducibility.\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8e9d5be7",
      "metadata": {
        "id": "8e9d5be7"
      },
      "outputs": [],
      "source": [
        "set_seeds()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a4ce2f",
      "metadata": {
        "id": "90a4ce2f"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc112c0e",
      "metadata": {
        "id": "dc112c0e"
      },
      "source": [
        "## Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "00f8a05a",
      "metadata": {
        "id": "00f8a05a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Optional\n",
        "from transformers import BaseImageProcessor\n",
        "from torchvision import transforms\n",
        "\n",
        "class FoodSeg103Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    A robust PyTorch Dataset wrapper for the Hugging Face FoodSeg103 dataset.\n",
        "\n",
        "    Each sample includes:\n",
        "        - image (PIL Image)\n",
        "        - label (segmentation mask as PIL Image)\n",
        "        - classes_on_image (list of class IDs present)\n",
        "        - id (int)\n",
        "\n",
        "    Supports:\n",
        "        - Hugging Face AutoImageProcessor (e.g., SegFormer processor)\n",
        "        - Optional torchvision transforms (fallback)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hf_dataset,\n",
        "        processor: Optional[BaseImageProcessor] = None,\n",
        "        transform: Optional[transforms.Compose] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hf_dataset: Hugging Face dataset split (e.g., from `datasets.load_dataset`).\n",
        "            processor: Optional Hugging Face processor (handles resizing, normalization, etc.).\n",
        "            transform: Optional torchvision-style transform (used when no processor is provided).\n",
        "        \"\"\"\n",
        "        self.dataset = hf_dataset\n",
        "        self.processor = processor\n",
        "        self.transform = transform\n",
        "\n",
        "        # Safety check: warn if neither processor nor transform is provided\n",
        "        if self.processor is None and self.transform is None:\n",
        "            print(\"‚ö†Ô∏è Warning: No processor or transform provided. \"\n",
        "                  \"Images will remain as PIL and may cause DataLoader errors.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Fetch and preprocess one sample from the dataset.\n",
        "        Returns:\n",
        "            (pixel_values, labels): both torch.Tensors\n",
        "        \"\"\"\n",
        "        item = self.dataset[idx]\n",
        "        image = item[\"image\"]   # PIL Image\n",
        "        label = item[\"label\"]   # PIL Image mask\n",
        "\n",
        "        # --- Option 1: Use Hugging Face processor (preferred for SegFormer) ---\n",
        "        if self.processor is not None:\n",
        "            encoded = self.processor(image, segmentation_maps=label, return_tensors=\"pt\")\n",
        "            pixel_values = encoded[\"pixel_values\"].squeeze(0)\n",
        "            labels = encoded[\"labels\"].squeeze(0).long()\n",
        "            return pixel_values, labels\n",
        "\n",
        "        # --- Option 2: Use torchvision transforms manually ---\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            # Fallback: convert PIL ‚Üí Tensor to avoid DataLoader crashes\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        label = np.array(label, dtype=np.int64)\n",
        "        label = torch.as_tensor(label, dtype=torch.long)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Return a clean summary of the dataset configuration.\"\"\"\n",
        "        transform_str = str(self.transform) if self.transform else \"None\"\n",
        "        processor_str = self.processor.__class__.__name__ if self.processor else \"None\"\n",
        "        split_name = getattr(self.dataset, \"split\", \"unknown\")\n",
        "        return (\n",
        "            f\"Dataset: FoodSeg103\\n\"\n",
        "            f\"    Number of datapoints: {len(self)}\\n\"\n",
        "            f\"    Split: {split_name}\\n\"\n",
        "            f\"    Processor: {processor_str}\\n\"\n",
        "            f\"    Transform: {transform_str}\\n\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Mappings"
      ],
      "metadata": {
        "id": "_ruQ_i7wOTeA"
      },
      "id": "_ruQ_i7wOTeA"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_class_mappings(json_path: str) -> Tuple[Optional[Dict[int, str]], Optional[Dict[int, str]]]:\n",
        "    \"\"\"\n",
        "    Load id2label and label2id mappings from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        json_path (str): Path to the JSON file like:\n",
        "            {\n",
        "              \"0\": \"background\",\n",
        "              \"1\": \"candy\",\n",
        "              \"2\": \"egg tart\",\n",
        "              ...\n",
        "            }\n",
        "\n",
        "    Returns:\n",
        "        tuple: (id2label: dict[int, str], label2id: dict[str, int])\n",
        "    \"\"\"\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Convert string keys to integers for id2label\n",
        "    id2label = {int(k): v for k, v in data.items()}\n",
        "    label2id = {v: int(k) for k, v in id2label.items()}\n",
        "\n",
        "    return id2label, label2id"
      ],
      "metadata": {
        "id": "YwBs7Ub0Uo3q"
      },
      "id": "YwBs7Ub0Uo3q",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label, label2id = load_class_mappings(\"/content/drive/MyDrive/datasets/foodSeg103/classnames.json\")\n",
        "\n",
        "print(\"First 5 id2label:\")\n",
        "print(dict(list(id2label.items())[:5]))\n",
        "\n",
        "print(\"\\nFirst 5 label2id:\")\n",
        "print(dict(list(label2id.items())[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3hKVRLikoqX",
        "outputId": "3ea6e812-a5ed-4ba5-d50c-cae9c9667735"
      },
      "id": "Q3hKVRLikoqX",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 id2label:\n",
            "{0: 'background', 1: 'candy', 2: 'egg tart', 3: 'french fries', 4: 'chocolate'}\n",
            "\n",
            "First 5 label2id:\n",
            "{'background': 0, 'candy': 1, 'egg tart': 2, 'french fries': 3, 'chocolate': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581c29de",
      "metadata": {
        "id": "581c29de"
      },
      "source": [
        "## Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ae275c84",
      "metadata": {
        "id": "ae275c84"
      },
      "outputs": [],
      "source": [
        "class Split(Enum):\n",
        "    TRAIN = \"train\"\n",
        "    VALIDATION = \"validation\"\n",
        "    TEST = \"test\"\n",
        "    ALL = \"all\"\n",
        "\n",
        "def create_dataloaders_from_hf(\n",
        "    dataset_name: str,\n",
        "    split: Split = Split.ALL,\n",
        "    processor: Optional[BaseImageProcessor] = None,\n",
        "    batch_size: int = 4,\n",
        "    num_workers: int = 2,\n",
        "    device: str = None\n",
        ") -> Tuple[Optional[torch.utils.data.DataLoader], Optional[torch.utils.data.DataLoader], Optional[torch.utils.data.DataLoader]]:\n",
        "    \"\"\"\n",
        "    Create PyTorch DataLoaders from a Hugging Face dataset like FoodSeg103.\n",
        "\n",
        "    Args:\n",
        "        dataset_name (str): Hugging Face dataset name.\n",
        "        transform: torchvision transforms to perform on data.\n",
        "        split (Split): Which split(s) to load (TRAIN, VALIDATION, TEST, or ALL).\n",
        "        batch_size (int): Batch size for DataLoaders.\n",
        "        num_workers (int): Number of DataLoader workers.\n",
        "    Returns:\n",
        "        (train_loader, val_loader, test_loader): Tuple of DataLoaders.\n",
        "        Unused splits will be returned as None.\n",
        "    \"\"\"\n",
        "\n",
        "    def build_loader(split_name: str, is_train: bool = False, device:str = None) -> torch.utils.data.DataLoader:\n",
        "        ds = load_dataset(dataset_name, split=split_name)\n",
        "        dataset = FoodSeg103Dataset(ds, processor=processor)\n",
        "        device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        pin_mem = True if device == \"cuda\" else False\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=is_train,\n",
        "            drop_last=is_train,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=pin_mem,\n",
        "        )\n",
        "\n",
        "    # --- Load splits ---\n",
        "    train_loader = val_loader = test_loader = None\n",
        "    if split in (Split.TRAIN, Split.ALL):\n",
        "        train_loader = build_loader(\"train\", is_train=True)\n",
        "\n",
        "    if split in (Split.VALIDATION, Split.ALL):\n",
        "        val_loader = build_loader(\"validation\")\n",
        "\n",
        "    if split in (Split.TEST, Split.ALL):\n",
        "        try:\n",
        "            test_loader = build_loader(\"test\")\n",
        "        except ValueError:\n",
        "            print(f\"‚ö†Ô∏è No 'test' split found in dataset: {dataset_name}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30aa13ae",
      "metadata": {
        "id": "30aa13ae"
      },
      "source": [
        "# Model Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7362b70f",
      "metadata": {
        "id": "7362b70f"
      },
      "source": [
        "## SegFormer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5107111e",
      "metadata": {
        "id": "5107111e"
      },
      "outputs": [],
      "source": [
        "from transformers import SegformerForSemanticSegmentation, SegformerConfig, SegformerImageProcessor, BaseImageProcessor\n",
        "\n",
        "class Segformer:\n",
        "    \"\"\"\n",
        "    A flexible builder for creating and configuring SegFormer models\n",
        "    from the Hugging Face Transformers library.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
        "        num_classes: int = 104,\n",
        "        ignore_mismatched_sizes: bool = True,\n",
        "        dropout: float = 0.1,\n",
        "        device: str = \"cuda\",\n",
        "        processor: Optional[BaseImageProcessor] = None,\n",
        "        id2label: Optional[Dict[int, str]] = None,\n",
        "        label2id: Optional[Dict[str, int]] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the SegformerBuilder.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Pretrained SegFormer model name or path.\n",
        "            num_classes (int): Number of segmentation classes.\n",
        "            ignore_mismatched_sizes (bool): Allow different output head sizes.\n",
        "            use_pretrained (bool): Whether to load pretrained weights.\n",
        "            device (str): Device to load model on (\"cuda\" or \"cpu\").\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.num_classes = num_classes\n",
        "        self.ignore_mismatched_sizes = ignore_mismatched_sizes\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.id2label = id2label\n",
        "        self.label2id = label2id\n",
        "\n",
        "        # Load model config Parameters\n",
        "        self.config = SegformerConfig.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=num_classes,\n",
        "            hidden_dropout_prob=dropout,\n",
        "            id2label=self.id2label,\n",
        "            label2id=self.label2id\n",
        "        )\n",
        "\n",
        "        # Load model weights\n",
        "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "            model_name,\n",
        "            config=self.config,\n",
        "            ignore_mismatched_sizes=ignore_mismatched_sizes\n",
        "        )\n",
        "        # Load image processor (for transforms)\n",
        "        self.processor = processor or AutoImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "        # Set model to device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def get_model(self) -> torch.nn.Module:\n",
        "        \"\"\"Return the PyTorch model.\"\"\"\n",
        "        return self.model\n",
        "\n",
        "    def get_processor(self):\n",
        "        \"\"\"Return the Hugging Face image processor for transforms.\"\"\"\n",
        "        return self.processor\n",
        "\n",
        "    def freeze_encoder(self, freeze=True):\n",
        "        \"\"\"Freeze or unfreeze the encoder layers.\"\"\"\n",
        "        for param in self.model.segformer.encoder.parameters():\n",
        "            param.requires_grad = not freeze\n",
        "        print(f\"Encoder frozen: {freeze}\")\n",
        "\n",
        "    def freeze_decoder(self, freeze=True):\n",
        "        \"\"\"Freeze or unfreeze the decoder layers.\"\"\"\n",
        "        for param in self.model.decode_head.parameters():\n",
        "            param.requires_grad = not freeze\n",
        "        print(f\"Decoder frozen: {freeze}\")\n",
        "\n",
        "    def unfreeze_all(self):\n",
        "        \"\"\"Unfreeze all parameters.\"\"\"\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "        print(\"All model parameters are trainable.\")\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Print basic info about the model.\"\"\"\n",
        "        print(\"\\nüß© SegFormer Model Summary\\n\")\n",
        "        print(f\"Model: {self.model_name}\")\n",
        "        print(f\"Classes: {self.num_classes}\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "        print(f\"Trainable: {sum(p.numel() for p in self.model.parameters() if p.requires_grad):,}\")\n",
        "        # Add shape info\n",
        "        size = self.processor.size.get(\"height\", 512)\n",
        "        dummy = torch.randn(1, 3, size, size).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            out = self.model(pixel_values=dummy)\n",
        "        print(f\"Output keys: {list(out.keys())}\")\n",
        "        print(f\"Logits shape: {out.logits.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainning Engine"
      ],
      "metadata": {
        "id": "pZCIMM3d4A8W"
      },
      "id": "pZCIMM3d4A8W"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6ce5bf0f",
      "metadata": {
        "id": "6ce5bf0f"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "def train_step(model, dataloader, scaler, optimizer, loss_fn, num_classes: int, device: str):\n",
        "    \"\"\"Run one training epoch.\"\"\"\n",
        "    model.train()\n",
        "    train_loss, train_acc, train_iou = 0, 0, 0\n",
        "    autocast_device = \"cuda\" if device == \"cuda\" else \"cpu\"\n",
        "\n",
        "    for images, labels in tqdm(dataloader, leave=False, desc=\"Training\"):\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        try:\n",
        "            # ---- Forward + Backward with AMP ----\n",
        "            with autocast(device_type=autocast_device, enabled=(device == \"cuda\")):\n",
        "                outputs = model(pixel_values=images)\n",
        "                logits = torch.nn.functional.interpolate(\n",
        "                    outputs.logits,\n",
        "                    size=labels.shape[-2:],\n",
        "                    mode=\"bilinear\",\n",
        "                    align_corners=False\n",
        "                )\n",
        "                loss = loss_fn(logits, labels)\n",
        "\n",
        "            # ---- Gradient Scaling ----\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # ---- Metrics ----\n",
        "            train_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            train_acc += pixel_accuracy(preds, labels)\n",
        "            train_iou += intersection_over_union(preds, labels, num_classes)\n",
        "\n",
        "            del loss, outputs, logits\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(\"‚ö†Ô∏è Skipping batch due to OOM error.\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return train_loss / n, train_acc / n, train_iou / n\n",
        "\n",
        "\n",
        "def eval_step(model, dataloader, loss_fn, num_classes: int, device: str):\n",
        "    \"\"\"Evaluate model for one epoch.\"\"\"\n",
        "    model.eval()\n",
        "    test_loss, test_acc, test_iou = 0, 0, 0\n",
        "    autocast_device = \"cuda\" if device == \"cuda\" else \"cpu\"\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in tqdm(dataloader, leave=False, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            with autocast(device_type=autocast_device, enabled=(device == \"cuda\")):\n",
        "                outputs = model(pixel_values=images)\n",
        "                logits = torch.nn.functional.interpolate(\n",
        "                    outputs.logits,\n",
        "                    size=labels.shape[-2:],\n",
        "                    mode=\"bilinear\",\n",
        "                    align_corners=False\n",
        "                )\n",
        "                loss = loss_fn(logits, labels)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_acc += pixel_accuracy(preds, labels)\n",
        "            test_iou += intersection_over_union(preds, labels, num_classes)\n",
        "\n",
        "            del loss, outputs, logits\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    n = len(dataloader)\n",
        "    return test_loss / n, test_acc / n, test_iou / n\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    epochs: int,\n",
        "    device: str,\n",
        "    num_classes: int,\n",
        "    scheduler=None,\n",
        "    save_dir: str = \"checkpoints\",\n",
        "    min_best_miou: float = 0.0,\n",
        "    vis_every: int = 5,\n",
        "    auto_save: bool = True,\n",
        "    max_keep_checkpoints: int = 3,  # üß† keep last 3 checkpoints only\n",
        "):\n",
        "    \"\"\"\n",
        "    Full training loop for semantic segmentation with:\n",
        "    - AMP training\n",
        "    - Auto resume from last checkpoint\n",
        "    - Auto save best model\n",
        "    - Keeps limited number of last checkpoints\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = torch.device(device)\n",
        "    scaler = GradScaler() if device.type == \"cuda\" else None\n",
        "    model.to(device)\n",
        "    best_miou = 0.0\n",
        "    start_epoch = 0\n",
        "\n",
        "    # ============================================================\n",
        "    # üîπ Helper: Find latest checkpoint by epoch number\n",
        "    # ============================================================\n",
        "    def _find_latest_checkpoint(path: str):\n",
        "        ckpts = [f for f in os.listdir(path) if f.startswith(\"last_checkpoint_\") and f.endswith(\".ckpt\")]\n",
        "        if not ckpts:\n",
        "            return None\n",
        "        ckpts.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))  # sort numerically by epoch\n",
        "        return os.path.join(path, ckpts[-1])\n",
        "\n",
        "    latest_ckpt_path = _find_latest_checkpoint(save_dir)\n",
        "    best_ckpt_path = os.path.join(save_dir, \"best_segformer.ckpt\")\n",
        "\n",
        "    # ============================================================\n",
        "    # üîπ Auto Resume from latest or best\n",
        "    # ============================================================\n",
        "    if latest_ckpt_path:\n",
        "        print(f\"üîÅ Resuming from latest checkpoint: {latest_ckpt_path}\")\n",
        "        ckpt = load_checkpoint(model, optimizer, scheduler, path=latest_ckpt_path, device=device)\n",
        "        best_miou = ckpt.get(\"best_miou\", 0.0)\n",
        "        start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
        "    elif os.path.exists(best_ckpt_path):\n",
        "        print(f\"üîÅ Resuming from best checkpoint: {best_ckpt_path}\")\n",
        "        ckpt = load_checkpoint(model, optimizer, scheduler, path=best_ckpt_path, device=device)\n",
        "        best_miou = ckpt.get(\"best_miou\", 0.0)\n",
        "        start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
        "    else:\n",
        "        print(\"üÜï Starting fresh training...\")\n",
        "\n",
        "    # ============================================================\n",
        "    # üîπ Logs\n",
        "    # ============================================================\n",
        "    results = {k: [] for k in [\"train_loss\", \"train_acc\", \"train_iou\",\n",
        "                               \"test_loss\", \"test_acc\", \"test_iou\", \"epoch_time\"]}\n",
        "\n",
        "    # ============================================================\n",
        "    # üîπ Training Loop\n",
        "    # ============================================================\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        start_time = time.perf_counter()\n",
        "        print(f\"\\nüå± Epoch [{epoch + 1}/{epochs}]\")\n",
        "\n",
        "        train_loss, train_acc, train_iou = train_step(model, train_dataloader, scaler, optimizer, loss_fn, num_classes, device)\n",
        "        test_loss, test_acc, test_iou = eval_step(model, test_dataloader, loss_fn, num_classes, device)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # ---- Logging ----\n",
        "        epoch_time = time.perf_counter() - start_time\n",
        "        results[\"epoch_time\"].append(epoch_time)\n",
        "        tqdm.write(\n",
        "            f\"üïí {epoch_time:.2f}s\\n\"\n",
        "            f\"üìà Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | mIoU: {train_iou:.4f}\\n\"\n",
        "            f\"üìà Val Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | mIoU: {test_iou:.4f}\\n\"\n",
        "        )\n",
        "\n",
        "        # ========================================================\n",
        "        # üîπ Save Best and Last Checkpoints\n",
        "        # ========================================================\n",
        "        if auto_save and test_iou > best_miou and test_iou >= min_best_miou:\n",
        "            best_miou = test_iou\n",
        "            save_checkpoint(\n",
        "                model, optimizer, scheduler,\n",
        "                epoch, best_miou,\n",
        "                path=save_dir,\n",
        "                filename=\"best_segformer.ckpt\"\n",
        "            )\n",
        "            print(f\"üèÜ New best model saved (mIoU={best_miou:.4f})\")\n",
        "\n",
        "        # Always save latest epoch checkpoint\n",
        "        last_ckpt_path = os.path.join(save_dir, f\"last_checkpoint_{epoch + 1}.ckpt\")\n",
        "        save_checkpoint(model, optimizer, scheduler, epoch, best_miou, path=save_dir, filename=os.path.basename(last_ckpt_path))\n",
        "\n",
        "        # ========================================================\n",
        "        # üîπ Limit number of checkpoints (avoid growth)\n",
        "        # ========================================================\n",
        "        ckpts = sorted(\n",
        "            [f for f in os.listdir(save_dir) if f.startswith(\"last_checkpoint_\")],\n",
        "            key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])\n",
        "        )\n",
        "        if len(ckpts) > max_keep_checkpoints:\n",
        "            oldest_ckpt = os.path.join(save_dir, ckpts[0])\n",
        "            os.remove(oldest_ckpt)\n",
        "            print(f\"üßπ Deleted old checkpoint: {oldest_ckpt}\")\n",
        "\n",
        "        # ========================================================\n",
        "        # üîπ Periodic Visualization\n",
        "        # ========================================================\n",
        "        if (epoch + 1) % vis_every == 0:\n",
        "            model.eval()\n",
        "            images, labels = next(iter(test_dataloader))\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            with torch.inference_mode():\n",
        "                outputs = model(pixel_values=images)\n",
        "                logits = torch.nn.functional.interpolate(\n",
        "                    outputs.logits,\n",
        "                    size=labels.shape[-2:],\n",
        "                    mode=\"bilinear\",\n",
        "                    align_corners=False\n",
        "                )\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "            plot_segmentation(\n",
        "                images, labels, preds, n=min(4, images.size(0)),\n",
        "                save_path=os.path.join(save_dir, f\"vis_epoch_{epoch + 1}.png\")\n",
        "            )\n",
        "            plot_training_curves(\n",
        "                results,\n",
        "                save_path=os.path.join(save_dir, \"training_curves.png\")\n",
        "            )\n",
        "\n",
        "        # ========================================================\n",
        "        # üîπ Record Metrics\n",
        "        # ========================================================\n",
        "        for k, v in zip([\"train_loss\", \"train_acc\", \"train_iou\", \"test_loss\", \"test_acc\", \"test_iou\"],\n",
        "                        [train_loss, train_acc, train_iou, test_loss, test_acc, test_iou]):\n",
        "            results[k].append(v)\n",
        "\n",
        "    # ============================================================\n",
        "    # üîπ Summary\n",
        "    # ============================================================\n",
        "    print(\"\\nüéØ Training complete!\")\n",
        "    print(f\"üèÜ Best Validation mIoU: {best_miou:.4f}\")\n",
        "    avg_time = np.mean(results[\"epoch_time\"])\n",
        "    print(f\"‚è±Ô∏è Avg Epoch Time: {avg_time:.2f}s\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d124c05a",
      "metadata": {
        "id": "d124c05a"
      },
      "source": [
        "## Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b909cb3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "b909cb3f",
        "outputId": "eca931ba-bfe8-4597-83f1-a67592a5570b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([104]) in the model instantiated\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([104, 256, 1, 1]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/EduardoPacheco/FoodSeg103/resolve/34e1208e14bc3595d544fc8c3f3c6673253fd9ef/FoodSeg103.py",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 api.hf_hub_download(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5467\u001b[0;31m         return hf_hub_download(\n\u001b[0m\u001b[1;32m   5468\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;31m# If we can't, a HEAD request error is returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{response.status_code} Client Error.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Entry Not Found for url: {response.url}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-690c922f-4e1ca6557d26a81d01cb11c2;ca5b1f21-dccb-4c17-8607-f3fadf4e66dc)\n\nEntry Not Found for url: https://huggingface.co/datasets/EduardoPacheco/FoodSeg103/resolve/34e1208e14bc3595d544fc8c3f3c6673253fd9ef/FoodSeg103.py.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4128431194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Initialize Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataloaders_from_hf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EduardoPacheco/FoodSeg103\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Loss (ignore_index=255 if present in dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3757524252.py\u001b[0m in \u001b[0;36mcreate_dataloaders_from_hf\u001b[0;34m(dataset_name, split, processor, batch_size, num_workers, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3757524252.py\u001b[0m in \u001b[0;36mbuild_loader\u001b[0;34m(split_name, is_train, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFoodSeg103Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   1393\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fix_for_backward_compatible_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0muse_exported_dataset_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 return HubDatasetModuleFactory(\n\u001b[0m\u001b[1;32m    997\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                     \u001b[0mcommit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, commit_hash, data_dir, data_files, download_config, download_mode, use_exported_dataset_infos)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_exported_dataset_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_exported_dataset_infos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mincrease_load_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDatasetModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mincrease_load_count\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_HUB_OFFLINE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_UPDATE_DOWNLOAD_COUNTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             get_session().head(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS3_DATASETS_BUCKET_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_datasets_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Send: {_curlify(request)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "LR = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "T_MAX = 20\n",
        "IGNORE_INDEX = 255\n",
        "CHECKPOINT_DIR = \"drive/MyDrive/ckpts\"\n",
        "NUM_WORKERS = os.cpu_count() or 2 # Use 2 Workers as default\n",
        "BATCH_SIZE = 8\n",
        "NUM_CLASSES = 104\n",
        "DROP_RATE = 0.1\n",
        "\n",
        "# Get Class Mappings\n",
        "id2label,label2id = load_class_mappings(\"drive/MyDrive/datasets/foodSeg103/classnames.json\")\n",
        "\n",
        "# Initialize model and builder\n",
        "builder = Segformer(num_classes=NUM_CLASSES, device=DEVICE, dropout=DROP_RATE, id2label=id2label, label2id=label2id)\n",
        "model = builder.get_model()\n",
        "# Get Image Processor from builder\n",
        "processor = builder.get_processor()\n",
        "\n",
        "# Initialize Dataloaders\n",
        "train_loader, validation_loader, _ = create_dataloaders_from_hf(dataset_name=\"EduardoPacheco/FoodSeg103\", batch_size=BATCH_SIZE, processor=processor)\n",
        "\n",
        "# Loss (ignore_index=255 if present in dataset)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
        "\n",
        "# Display Summary\n",
        "print(builder.summary())\n",
        "\n",
        "# Fine-tune\n",
        "if __name__ == \"__main__\":\n",
        "    results = train(\n",
        "    model=model,\n",
        "    train_dataloader=train_loader,\n",
        "    test_dataloader=validation_loader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    epochs=EPOCHS,\n",
        "    device=DEVICE,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    scheduler=scheduler,\n",
        "    save_dir=CHECKPOINT_DIR,\n",
        "    vis_every=10,  # visualize predictions every 10 epochs\n",
        "    auto_save=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "854c2b4b",
      "metadata": {
        "id": "854c2b4b"
      },
      "source": [
        "## Export Checkpoint for Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e71f56",
      "metadata": {
        "id": "11e71f56"
      },
      "outputs": [],
      "source": [
        "# Save Hugging Face compatible export\n",
        "save_huggingface_export(model, processor, export_dir=\"/drive/MyDrive/ckpts/segformer_finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "fonwwG0MuPxw"
      },
      "id": "fonwwG0MuPxw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Saved Model"
      ],
      "metadata": {
        "id": "h2nMRVBsbHQV"
      },
      "id": "h2nMRVBsbHQV"
    },
    {
      "cell_type": "code",
      "source": [
        "load_huggingface_export(model, path=\"/drive/MyDrive/ckpts/segformer_best.ckpt\", device=builder.device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "bZmqjFThbGK9"
      },
      "id": "bZmqjFThbGK9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Curves"
      ],
      "metadata": {
        "id": "QpIANSequXEw"
      },
      "id": "QpIANSequXEw"
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(training_results, save_path=\"models/checkpoints/training_plots.png\")"
      ],
      "metadata": {
        "id": "jrRIs6A-uqym"
      },
      "id": "jrRIs6A-uqym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Training Time"
      ],
      "metadata": {
        "id": "sUXiJO9Funmv"
      },
      "id": "sUXiJO9Funmv"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_time(results, save_path=None):\n",
        "    \"\"\"Plot time taken per epoch and display total + average.\"\"\"\n",
        "    epoch_times = results.get(\"epoch_time\", [])\n",
        "    if not epoch_times:\n",
        "        print(\"[WARN] No epoch_time data found in results.\")\n",
        "        return\n",
        "\n",
        "    epochs = range(1, len(epoch_times) + 1)\n",
        "    avg_time = np.mean(epoch_times)\n",
        "    total_time = np.sum(epoch_times)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, epoch_times, marker='o', color='mediumseagreen', linewidth=2)\n",
        "    plt.title(\"‚è±Ô∏è Training Time per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Time (seconds)\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.xticks(epochs)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "        print(f\"‚úÖ Saved training time plot to {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "    print(f\"üìä Total Training Time: {total_time:.2f} seconds\")\n",
        "    print(f\"‚öôÔ∏è  Average Epoch Time: {avg_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "IjQx-Szdul0q"
      },
      "id": "IjQx-Szdul0q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_time(results, save_path=\"models/checkpoints/training_time.png\")"
      ],
      "metadata": {
        "id": "9BzCiM6AWdaT"
      },
      "id": "9BzCiM6AWdaT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Predictions"
      ],
      "metadata": {
        "id": "m_lHJTU7Wgbf"
      },
      "id": "m_lHJTU7Wgbf"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def visualize_predictions(model, dataloader, device, id2label, num_samples=4):\n",
        "    \"\"\"Visualize a few segmentation predictions with class colors.\"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    images, labels = next(iter(dataloader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(pixel_values=images)\n",
        "        logits = torch.nn.functional.interpolate(\n",
        "            outputs.logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "        preds = torch.argmax(logits, dim=1).cpu()\n",
        "\n",
        "    # Display a few samples\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "        pred_mask = preds[i].numpy()\n",
        "        true_mask = labels[i].cpu().numpy()\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "        ax[0].imshow(img)\n",
        "        ax[0].set_title(\"Original Image\")\n",
        "\n",
        "        ax[1].imshow(true_mask, cmap=\"tab20\")\n",
        "        ax[1].set_title(\"Ground Truth\")\n",
        "\n",
        "        ax[2].imshow(pred_mask, cmap=\"tab20\")\n",
        "        ax[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "        for a in ax: a.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "wovyxqJ5VKBM"
      },
      "id": "wovyxqJ5VKBM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(model, validation_loader, builder.device, builder.id2label, num_samples=4)"
      ],
      "metadata": {
        "id": "UvU2dkYNWj9-"
      },
      "id": "UvU2dkYNWj9-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}